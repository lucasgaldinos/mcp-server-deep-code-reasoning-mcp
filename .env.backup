# ============================================================================
# Environment Configuration for Deep Code Reasoning MCP Server
# ============================================================================

# REQUIRED CONFIGURATION
GEMINI_API_KEY="AIzaSyA8_vKaVp-tGm_GFLg0Ori0-NaphG7-V8U"
# FREE TIER MODEL CONFIGURATION (Updated September 2025)
GEMINI_MODEL=gemini-2.5-flash
GEMINI_API_VERSION=v1beta

# Node.js Environment
NODE_ENV=development

# Server Configuration
MCP_SERVER_NAME=deep-code-reasoning-mcp
MCP_SERVER_VERSION=0.1.0
REQUEST_TIMEOUT=30000
MAX_CONCURRENT_REQUESTS=5

# Model Parameters (Optimized for free tier)
GEMINI_TEMPERATURE=0.2
GEMINI_TOP_K=1
GEMINI_TOP_P=1
GEMINI_MAX_OUTPUT_TOKENS=8192

# Free tier rate limiting (10 RPM for gemini-2.5-flash)
GEMINI_REQUESTS_PER_MINUTE=8
GEMINI_BURST_LIMIT=2
GEMINI_MAX_RETRIES=3
GEMINI_BACKOFF_DELAY=2000

# Logging
LOG_LEVEL=info
LOG_TO_CONSOLE=true
ENABLE_DEBUG_LOGGING=false